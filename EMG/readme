This repository contains jupyter notebooks used to process electromyography data. There are two ways to process these data:

Method One: set up data stride by stride resulting in a matrix with 1196 strides. This is advantageous for training machine learning models.
Method Two: average each subjects n strides at each time point together, resulting in a matrix with 96 total data points. 

1. Extract all stride data from Visual 3D. Store data in sepearate files for each subject and each timepoint.
2. Run EMG_resampling_to_101: resamples each stride to 101 data points, a traditional method in biomechanics research
3. Run EMG_normalization_by_subject or EMG_normalization_by_muscle to normalize the EMG data to the maximum muscle activity for each stride. There was no MVIC recorded,
   so this is the most appropriate normalization methodology available. 
4. Run EMG_metric_waveform_matrices to generate a matrix for each muscle. Within the notebook, adjust the file paths if you want to use method one (strides) or method 
   two (means). 
5. Run all_group_concatenator to concatenate each group (healthy, injured, recovered) into one matrix. This is necessary to run the principal component analysis because
   you need each group included in the matrix to generate PC scores.
6. Run EMG_PCA_individual_muscles (method one) or EMG_PCA_subject_means (method two). Change the muscle of interest each time you run the script. It will output three
   matrices per muscle: principal component scores, explained variance for each PC, and the loadings. 

Once all these steps are complete, move to PFP_project/machine_learning to generate matrices of PC scores and run respective machine learning models.
